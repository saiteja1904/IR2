{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CZ4034_Rescraping.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5pOALB2gWNF2"
      },
      "source": [
        "# CZ4034 Information Retrieval - Group 17\n",
        "\n",
        "## Crawling Python Notebook (with Data Cleaning)\n",
        "\n",
        "### This notebook contains the main code used for Crawling/Scraping Twitter using SNScrape, with some of the Data Cleaning code."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0hefAiTflC4Z"
      },
      "source": [
        "import pandas as pd\n",
        "import snscrape.modules.twitter as sntwitter\n",
        "import itertools\n",
        "import time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yOA_hXPQlC4Z"
      },
      "source": [
        "# Python Dictionary of Countries mapped to their Main Cities (usually Capital Cities)\n",
        "countriesDict = {\n",
        "    \"Iran\":\"Tehran\", \"Israel\":\"Jerusalem\", \n",
        "    \"Saudi Arabia\":\"Riyadh\", \"China\":\"Hong Kong\",\n",
        "    \"Ukraine\":\"Kyiv\", \"Russia\":\"Moscow\",\n",
        "    \"UK\":\"London\", \"India\":\"New Delhi\", \n",
        "    \"Mexico\":\"Mexico City\", \"Canada\":\"Ottawa\", \n",
        "    \"Brazil\":\"Brasilia\", \"South Korea\":\"Seoul\",\n",
        "    \"Philippines\":\"Manila\", \"Kenya\":\"Nairobi\",\n",
        "    \"Nigeria\":\"Abuja\",\"Germany\":\"Berlin\",\n",
        "    \"Taiwan\":\"Taipei\",\"France\":\"Paris\",\n",
        "    \"Afghanistan\":\"Kabul\", \"Indonesia\":\"Jakarta\",\n",
        "    \"Japan\":\"Tokyo\", \"Australia\":\"Canberra\",\n",
        "    \"Singapore\":\"Singapore\"\n",
        "}\n",
        "\n",
        "num_tweets_per_tag = 5000"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h1o6dH-1lC4a"
      },
      "source": [
        "# Keywords\n",
        "keywords = [ \n",
        "            # Mentions of Trump: 7\n",
        "            \"#Trump\", \"#trump\", \"#Trump2020\", \"#DonaldTrump\", \"DonaldJTrump\", \"Donald Trump\", \"Trump\"\n",
        "            \n",
        "            # Pro-Trump: 8\n",
        "            '#VoteTrump', \"VoteRed\", \"#MAGA\", \"#PresidentTrump\",  '#MakeAmericaGreatAgain', '#TeamTrump',  '#DrainTheSwamp',  \"#MyPresident\",\n",
        "            \n",
        "            # Anti-Trump: 7\n",
        "            \"#VoteTrumpOut\", \"#DumpTrump\", '#TrumpIsPathetic', '#TrumpCorruption', '#VoteHimOut', '#YoureFiredTrump', '#TrumpHasToGo',\n",
        "            \n",
        "            # Mentions of Biden: 6\n",
        "            \"#Biden\", \"#biden\", \"#Biden2020\", \"Joe Biden\", \"#JoeBiden\", \"Biden\",\n",
        "            \n",
        "            # Pro-Biden: 6\n",
        "            \"#VoteBiden\", \"VoteBlue\", \"#VoteBlueToSaveAmerica\", \"#BlueWave2020\", '#TeamBiden', '#JoeMentum', \n",
        "            \n",
        "            # Anti-Biden: 7\n",
        "            \"Sleepy Joe\", \"#SleepyJoe\", \"HidenBiden\", \"#CreepyJoeBiden\", \"#NeverBiden\", \"#BidenUkraineScandal\", '#HunterBiden',\n",
        "            \n",
        "            # Miscellaneous: 1\n",
        "            \"#USElections\"\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Brv_8VLblC4a",
        "scrolled": true
      },
      "source": [
        "# This is the main method used to scrape Twitter data (tweets) using SNScrape\n",
        "def scrape_data(countryName, countriesDict=countriesDict, withinRange = 1000, num_tweets_per_tag=num_tweets_per_tag):\n",
        "    start = time.time()\n",
        "    df = pd.DataFrame()\n",
        "    for word in keywords:\n",
        "        try:\n",
        "            df = df.append(pd.DataFrame(itertools.islice(sntwitter.TwitterSearchScraper(\n",
        "                f'{word} near:\"{countriesDict[countryName]}\" within:{withinRange}km lang:en since:2020-09-01 until:2020-12-31').get_items(), num_tweets_per_tag)))\n",
        "        except Exception as e:\n",
        "            print(f\"An error occured: :(\\n\")\n",
        "            continue\n",
        "    if len(df) < 1000:\n",
        "        print(f\"Number of tweets for {countryName} is lower than expected! df shape: {df.shape}\")\n",
        "    df['username'] =  df['user'].apply(lambda x: x['username'])\n",
        "    df['country'] = countryName\n",
        "    df_ = df[[\"username\", \"content\", \"date\", \"country\", \"replyCount\", \"retweetCount\", \"likeCount\", \"url\"]]\n",
        "    df_.to_csv(f'snscrape_{countryName}.csv', index = False)\n",
        "    print(f\"Shape of df for {countryName}: {df_.shape}, Time taken: {((time.time() - start)/60):.1f} mins\")\n",
        "    return df_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3aWn9FgSnYEZ"
      },
      "source": [
        "# Initializing Dictionary of DataFrames for Each of the 23 Countries\n",
        "countriesDf = {}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "wSx77FwanYEZ"
      },
      "source": [
        "# This code block scrapes data for each country in the countriesDict dictionary.\n",
        "# For some countries, the range parameter for SNScrape has been specified.\n",
        "\n",
        "for country in countriesDict.keys():\n",
        "    if country in countriesDf.keys():\n",
        "        continue\n",
        "    if country in ['Russia']:\n",
        "        withinRange=1000\n",
        "    elif country in ['Mexico']:\n",
        "        withinRange=500\n",
        "    elif country in ['Canada']:\n",
        "        withinRange=100\n",
        "    elif country in ['Singapore']:\n",
        "        withinRange=50\n",
        "    else:\n",
        "        withinRange=800\n",
        "    countriesDf[country] = scrape_data(country, withinRange=withinRange)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v464yNX-nYEd"
      },
      "source": [
        "# To check the Number of Tweets found for each Country\n",
        "for country, countryDf in countriesDf.items():\n",
        "    print(f\"{country}: {len(countryDf)}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wrd78MgClC4c"
      },
      "source": [
        "# To create the main DataFrame of tweets\n",
        "df = pd.DataFrame()\n",
        "for countryDf in countriesDf.values():\n",
        "    df = df.append(countryDf)\n",
        "\n",
        "print(df.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PXmxK8HUlC4c"
      },
      "source": [
        "# Cleaning Data\n",
        "df_indexes_v2 = []\n",
        "user_dict = {}\n",
        "for i in range(len(df)):\n",
        "    tweet = df[\"content\"].iloc[i]\n",
        "    \n",
        "    # To remove tweets that have more hashtags than normal text\n",
        "    word_list = tweet.lower().split()\n",
        "    num_normal = 0\n",
        "    num_tags = 0\n",
        "    for j in range(len(word_list)):\n",
        "        temp = word_list[j]\n",
        "        if temp[0] == '#':\n",
        "            num_tags += 1\n",
        "        else:\n",
        "            num_normal += 1\n",
        "    if num_tags > num_normal:\n",
        "        continue\n",
        "    \n",
        "    # To choose only the latest tweet from a user to prevent multiple tweets from same user\n",
        "    user = df[\"username\"].iloc[i]\n",
        "    user_dict[user] = i\n",
        "    \n",
        "for value in user_dict.values():\n",
        "    df_indexes_v2.append(value)\n",
        "\n",
        "df_v2 = df.iloc[df_indexes_v2]\n",
        "print(f'Shape of df after cleaning: {df_v2.shape}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1GwEDhkInYEe"
      },
      "source": [
        "# Shuffling tweets in version 2 of the dataframe, and saving to a CSV file\n",
        "df_v2 = df_v2.drop_duplicates(subset='content')\n",
        "df_v2 = df_v2.sample(frac=1).reset_index(drop=True)\n",
        "print(df_v2.shape)\n",
        "df_v2.to_csv(\"cz4034_scraped_data.csv\", encoding = \"utf-8-sig\", index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RI3lW51dnYEg"
      },
      "source": [
        "# To print the unique countries in the DataFrame\n",
        "print(df_v2['country'].unique())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQNLd57vnYEg"
      },
      "source": [
        "# To print the number of tweets for each country\n",
        "print(df_v2.groupby('country')['content'].nunique())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vWqVx2G3nYEg"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}